{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import os\n",
    "import import_ipynb\n",
    "\n",
    "from kernel_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "BATCH = 1024\n",
    "EPOCH = 100\n",
    "ROWS = 10 ** 6\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "train_df = pd.read_csv('input/train.csv', nrows = ROWS)\n",
    "test_df = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check null value\n",
    "print(test_df.isnull().sum())\n",
    "#check zero value\n",
    "print((test_df == 0).astype(int).sum(axis=0))\n",
    "# the test data is very clean, with no null value or zero value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check description\n",
    "test_df.describe()\n",
    "# By checking the description of test data, we can see the min and max value of each feature, \n",
    "# so we can choose the clean the train data base on these value. In other word, we can delete \n",
    "# the values that are out of these boundaries in the train data, as they are using in training \n",
    "# the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check null value \n",
    "print(train_df.isnull().sum())\n",
    "#check zero value \n",
    "print((train_df == 0).astype(int).sum(axis=0))\n",
    "# There are some null and zero values in the train data. This step is very import, \n",
    "# as these values can influence the training result significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check description\n",
    "train_df.describe()\n",
    "# There are some values that are apparently to be wrong. E.g. the min of fare_amount is negative, but it can't be.\n",
    "# The max value of passenger count is 208, which is too exagerating. We have to delete this values. But it doesn't \n",
    "# matter, we will delete the useless value base on the value boundary in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete null value\n",
    "print(\"old: %d\" %len(train_df))\n",
    "train_df = train_df.dropna(how = 'any', axis = 'rows')\n",
    "print(\"new: %d\" %len(train_df)) # track data amount before and after deletion\n",
    "\n",
    "# Delete zero value\n",
    "print(\"old: %d\" %len(train_df))\n",
    "train_df = train_df[~(train_df == 0).any(axis=1)]\n",
    "print(\"new: %d\" %len(train_df)) # track data amount before and after deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min value of the fare_amount is less than zero and min passenger count is zero. We should discard those values.\n",
    "train_df = normalize_fare_passenger(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the 'pickup_datetime' column\n",
    "\n",
    "# Apply to both train and test data   \n",
    "train_df = convert_to_datetime(train_df)\n",
    "test_df = convert_to_datetime(test_df)\n",
    "\n",
    "# Check shape\n",
    "print (test_df.shape)\n",
    "print (train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date attributes and then drop the pickup_datetime column\n",
    "\n",
    "# Apply to both train and test data      \n",
    "train_df = extract_date(train_df)\n",
    "test_df = extract_date(test_df)\n",
    "\n",
    "# Check shape\n",
    "print (test_df.shape)\n",
    "print (train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are extra charges if trip ends in 3 nearby aiports and 7 nearby counties from the NYC center,\n",
    "# so these location points and there distances to pickup and dropoff points are key factors \n",
    "\n",
    "# Apply to both train and test data      \n",
    "train_df = transform(train_df)\n",
    "test_df = transform(test_df)\n",
    "\n",
    "# Check shape\n",
    "print (test_df.shape)\n",
    "print (train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider extra charges\n",
    "\n",
    "# Apply to both train and test data      \n",
    "train_df = final_convert(train_df)\n",
    "test_df = final_convert(test_df)\n",
    "\n",
    "# Check shape\n",
    "print (test_df.shape)\n",
    "print (train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop key\n",
    "train_df.drop(['key'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTLIER DETECTION (Mean-Std)\n",
    " \n",
    "print(\"old lenght: %d\" %len(train_df))\n",
    "train_df = outlier_analysis(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected after outlier detection, that columns returns 0 row after analysis\n",
    "train_df.drop(['county_dropoff_1', 'county_dropoff_2', 'night_hour', 'peak_hour', 'to_from_jfk', 'jfk_rush_hour', 'ewr'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fare_amount histogram\n",
    "draw_histogram(train_df, 'fare_amount', color='#A9C5D3', edge_color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_list = [0, .25, .5, .75, 1.]\n",
    "quantile_labels = ['0-25Q', '25-50Q', '50-75Q', '75-100Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptive Binning can be used\n",
    "train_df = create_bin_labels(train_df, 'fare_amount', quantile_list, quantile_labels)\n",
    "train_df[['fare_amount', 'fare_amount_bin_custom_range', 'fare_amount_bin_custom_label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE SELECTION\n",
    "fare_drop_df = train_df.drop(['fare_amount', 'fare_amount_bin_custom_range', 'fare_amount_bin_custom_label'], axis=1)\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(fare_drop_df[:10000], train_df['fare_amount_bin_custom_label'][:10000])\n",
    "\n",
    "for i, j in zip(fare_drop_df.columns, model.feature_importances_):\n",
    "    print(\"%s -> %s\"%(i, round(j, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fare_amount_bin_custom_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select important features\n",
    "train_df = train_df[['fare_amount', 'pickup_longitude', 'dropoff_distance_to_center', 'pickup_distance_to_Suffolk', 'dropoff_distance_to_Dutchess', 'pickup_distance_to_lgr', 'dropoff_distance_to_lgr']]\n",
    "test_df = test_df[['key','pickup_longitude', 'dropoff_distance_to_center', 'pickup_distance_to_Suffolk', 'dropoff_distance_to_Dutchess', 'pickup_distance_to_lgr', 'dropoff_distance_to_lgr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df.drop('fare_amount', axis=1),\n",
    "                                                    train_df['fare_amount'], test_size=0.2)\n",
    "\n",
    "# Check shape\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history, model = run_sequential_model(X_train, X_test, y_train, y_test, BATCH, EPOCH, LEARNING_RATE, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE MODEL AND WEIGHTS\n",
    "save_model_and_weights(model, \"model.json\", \"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD MODEL AND WEIGHTS\n",
    "load_model_and_weights(model, \"model.json\", \"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_build(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_build_train_val_ratio(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_build_mse(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating DNN submission\n",
    "pred_y = model.predict([test_df.drop(['key'], axis=1)])\n",
    "test_df['pred'] = pred_y\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test_df.key, 'fare_amount': test_df.pred},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('submission_dnn.csv', index = False)\n",
    "\n",
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
