{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import math\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adadelta\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('input/train.csv', nrows = 10 ** 6)\n",
    "test_df = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove null rows\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df.dropna(how = 'any', axis = 'rows')\n",
    "print('New size: %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min value of the fare_amount is less than zero and min passenger count is zero. We should discard those values.\n",
    "def normalize_fare_passenger(df):\n",
    "    if 'fare_amount' in df.columns:\n",
    "        print(\"old lenght: %d\" %len(df))\n",
    "        df = df[df.fare_amount>0]\n",
    "    print(\"length after fare_amount normalization: %d\" %len(df))\n",
    "    df = df[df.passenger_count>0]\n",
    "    print(\"length after passenger_count normalization: %d\" %len(df))\n",
    "    return df\n",
    "\n",
    "train_df = normalize_fare_passenger(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc haversine distance\n",
    "def calc_haversine(df):\n",
    "    R = 6371\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "    df['dlat'] = np.radians(df.dropoff_latitude - df.pickup_latitude)\n",
    "    df['dlon'] = np.radians(df.dropoff_longitude - df.pickup_longitude)\n",
    "    df['haversine_a'] = np.sin(df.dlat/2) * np.sin(df.dlat/2) + np.cos(np.radians(df.pickup_latitude)) \\\n",
    "            * np.cos(np.radians(df.dropoff_latitude)) * np.sin(df.dlon/2) * np.sin(df.dlon/2)\n",
    "    df['haversine'] = R * 2 * np.arctan2(np.sqrt(df.haversine_a), np.sqrt(1-df.haversine_a))\n",
    "\n",
    "    return df.drop(columns=['pickup_datetime'])\n",
    "\n",
    "train_df = calc_haversine(train_df)\n",
    "test_df = calc_haversine(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter interesting columns and label\n",
    "train_y = np.array(train_df['fare_amount'])\n",
    "train_X = train_df.drop(columns=['fare_amount','key'])\n",
    "\n",
    "print(\"Shape for X:\")\n",
    "print(train_X.shape)\n",
    "print(\"Shape for Y:\")\n",
    "print(train_y.shape)\n",
    "\n",
    "test_X = test_df.drop(columns=['key'])\n",
    "print(\"Shape for test X:\")\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X, Y, dnn_layers_size, dropout_value, batch_size, epochs):\n",
    "    \n",
    "    input_size = X.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for idx, l in enumerate(dnn_layers_size):\n",
    "        model.add(Dense(l, input_dim=input_size,\n",
    "                           kernel_initializer='normal',\n",
    "                           activation='selu'))\n",
    "        model.add(Dropout(dropout_value))\n",
    "        input_size = l\n",
    "        \n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    train_history = model.fit([X], Y, epochs=epochs, batch_size=batch_size, validation_split=0.1, shuffle=True)\n",
    "    \n",
    "    return train_history, model\n",
    "\n",
    "def build_layers(layers, n_features):\n",
    "    if len(layers) == 0:\n",
    "        n_features = int(n_features * 2.5)\n",
    "    else:\n",
    "        n_features = int(math.sqrt(n_features))\n",
    "        \n",
    "    if n_features < 3:\n",
    "        return layers\n",
    "    else:\n",
    "        layers.append(n_features)\n",
    "        return build_layers(layers, n_features)\n",
    "    \n",
    "def plot_build(train_history):    \n",
    "    \n",
    "    # plotting train_history\n",
    "    plt.figure(0)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0,90])\n",
    "    plt.plot(train_history.history['loss'],'g')\n",
    "    plt.plot(train_history.history['val_loss'],'b')\n",
    "    plt.rcParams['figure.figsize'] = (8, 6) \n",
    "    plt.xlabel(\"Num of Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss vs Validation Loss\")\n",
    "    plt.grid()\n",
    "    plt.legend(['train','validation'])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_build_train_val_ratio(train_history):    \n",
    "    \n",
    "    # plotting train_history\n",
    "    plt.figure(0)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0,5])\n",
    "    plt.plot([x/y for x, y in zip(train_history.history['loss'], train_history.history['val_loss'])],'g')\n",
    "    plt.rcParams['figure.figsize'] = (8, 6) \n",
    "    plt.xlabel(\"Num of Epochs\")\n",
    "    plt.ylabel(\"Loss / Val_loss\")\n",
    "    plt.title(\"Training Loss and Validation Loss Ratio\")\n",
    "    plt.grid()\n",
    "    plt.legend(['ratio'])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = build_layers([],train_X.shape[1])\n",
    "print('Layers:', layers)\n",
    "print('-' * 15)\n",
    "\n",
    "#train_X.drop(columns=['passenger_count'], axis=1, inplace=True)\n",
    "\n",
    "train_history, model = run_model(train_X, train_y, layers, 0.2, batch_size = 32, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_build(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_build_train_val_ratio(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating DNN submission\n",
    "pred_y = model.predict([test_X])\n",
    "test_df['pred'] = pred_y\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test_df.key, 'fare_amount': test_df.pred},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('submission_dnn.csv', index = False)\n",
    "\n",
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
